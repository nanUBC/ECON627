{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(joinpath(pwd(),\"..\"))\n",
    "using Random, Distributions, PrettyTables, Printf, Plots, Optim, ForwardDiff\n",
    "Random.seed!(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a): Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const θ_0 = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Λ(X, θ)\n",
    "    Λ = 2 * (1 .+ exp.(5 .- θ .* X)).^(-1)\n",
    "    return Λ = Λ\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function data(n)\n",
    "    Z1 = rand(Normal(2,1),n)\n",
    "    Z2 = rand(Normal(-2,1),n)\n",
    "    V = rand(Normal(0,1),n)\n",
    "    ϵ = rand(Normal(0,1),n)\n",
    "    \n",
    "    U = 0.9 * V + ϵ\n",
    "    X = exp.(Z1 + Z2) + V\n",
    "\n",
    "    Y = Λ(X, θ_0) + U\n",
    "\n",
    "    return (Y = Y, X = X, Z1 = Z1, Z2 = Z2)\n",
    "\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b): Criterion function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Qn(Y, X, Z1, Z2, θ, A)\n",
    "    n = length(Y)\n",
    "    Z = [Z1 Z2]\n",
    "    U = Y - Λ(X,θ)\n",
    "    Qn =  1/2 * (Z' * U/n)' * A * (Z' * U/n)\n",
    "    return Qn = Qn\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1 0; 0 1]\n",
    "n = 10^5\n",
    "\n",
    "result = zeros((400,2))\n",
    "(Y, X, Z1, Z2) = data(n)\n",
    "for i in 1:400\n",
    "    θ_i = -20 + 0.1 * i\n",
    "    result[i,1] = Qn(Y, X, Z1, Z2, θ_i, A)\n",
    "    result[i,2] = θ_i\n",
    "end\n",
    "\n",
    "plot(result[:,2], result[:,1], label = \"Qn\")\n",
    "vline!([result[argmax(result[:,1]),2]], label = \"Max Qn\")\n",
    "vline!([result[argmin(result[:,1]),2]], label = \"Min Qn\")\n",
    "vline!([5.0], label = \"Ture θ_0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This criterion function successfully identified $\\theta_0$, since the argmin of $Q_n$ is very close to $\\theta_0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = [1 0; 0 1]\n",
    "n = 10^5\n",
    "\n",
    "(Y, X, Z1, Z2) = data(n)\n",
    "\n",
    "result = optimize(θ -> Qn(Y, X, Z1, Z2, θ, A), [-5.0], NewtonTrustRegion(); autodiff = :forward)\n",
    "θ_1 = Optim.minimizer(result)\n",
    "\n",
    "result = optimize(θ -> Qn(Y, X, Z1, Z2, θ, A), [0.0], NewtonTrustRegion(); autodiff = :forward)\n",
    "θ_2 = Optim.minimizer(result)\n",
    "\n",
    "result = optimize(θ -> Qn(Y, X, Z1, Z2, θ, A), [20.0], NewtonTrustRegion(); autodiff = :forward)\n",
    "θ_3 = Optim.minimizer(result)\n",
    "\n",
    "\n",
    "print(θ_1, θ_2, θ_3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, when we start from a positive value, the solutions correctly point to the optimal $\\theta$, while it stays at the starting point if we starts from $-5$. I guess, with this method, Julia will only search along the direction that makes the criterion function lower. Therefore, if we start from a negative number, Julia won't search the right side. Moreover, it can also detect that there is no minimum on the left side, which makes it stop searching. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With efficient weighting matrix, we have:\n",
    "\n",
    "\\begin{equation}\n",
    "A_n^{*'} A_n^* \\longrightarrow_p A^{*'} A^* = (E[g(W_i, \\theta_0) g(W_i, \\theta_0)'])^{-1}  =\\Omega_0^{-1}\n",
    "\\end{equation}\n",
    "\n",
    "Therefore, we have:\n",
    "\n",
    "\n",
    "$$\n",
    "\\frac{\\partial^2 Q_n^*(\\theta_0)}{\\partial \\theta \\partial \\theta'} = \\left[ \\frac{1}{n} \\sum_{i = 1}^n  \\frac{\\partial g(W_i, \\theta_0)}{\\partial \\theta'}  \\right]' A_n^{*'} A_n^* \\left[ \\frac{1}{n} \\sum_{i = 1}^n  \\frac{\\partial g(W_i, \\theta_0)}{\\partial \\theta'}  \\right] + \\left[ \\frac{1}{n} \\sum_{i = 1}^n  \\frac{\\partial^2 g(W_i, \\theta_0)}{\\partial \\theta \\partial \\theta'}  \\right]' A_n^{*'} A_n^* \\left[ \\frac{1}{n} \\sum_{i = 1}^n   g(W_i, \\theta_0) \\right] $$\n",
    "\n",
    "$$ \\longrightarrow_p E\\left[ \\frac{\\partial g(W_i, \\theta_0)}{\\partial \\theta'}  \\right]' A^{*'} A^* E\\left[ \\frac{\\partial g(W_i, \\theta_0)}{\\partial \\theta'}  \\right]  = \\Gamma_0' \\Omega_0^{-1} \\Gamma_0 = V_0^{-1} \\\\\n",
    "$$\n",
    "\n",
    "Since we can estimate $\\theta_0$ consistantly,\n",
    "\n",
    "$$\n",
    "\\left( \\frac{\\partial^2 Q_n^*(\\hat{\\theta}_n)}{\\partial \\theta \\partial \\theta'} \\right)^{-1} = \\left( \\frac{\\partial^2 Q_n^*(\\theta_0)}{\\partial \\theta \\partial \\theta'} + \\frac{\\partial^3 Q_n^*(\\theta_0)}{\\partial \\theta \\partial \\theta' \\partial \\theta'} (\\hat{\\theta}_n - \\theta_0) \\right)^{-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\longrightarrow_p V_0\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function TwoStepGMM(Y,X, Z1, Z2)\n",
    "    A = [1 0; 0 1]\n",
    "    n = length(Y)\n",
    "    result1 = optimize(θ -> Qn(Y, X, Z1, Z2, θ, A), [0.0], NewtonTrustRegion(); autodiff = :forward)\n",
    "    θ_1 = Optim.minimizer(result1)\n",
    "    θ_1 = θ_1[1]\n",
    "\n",
    "    Z = [Z1 Z2]\n",
    "    U = Y - Λ(X,θ_1)\n",
    "    ZU = Z .* U\n",
    "\n",
    "    A1 = (ZU' * ZU) /n\n",
    "    A1 = inv(A1)\n",
    "\n",
    "    result2 = optimize(θ -> Qn(Y, X, Z1, Z2, θ, A1), [θ_1], NewtonTrustRegion(); autodiff = :forward)\n",
    "    θ_2 = Optim.minimizer(result2)\n",
    "    θ_2 = θ_2[1]\n",
    "\n",
    "    f(θ) = Qn(Y, X, Z1, Z2, θ, A1)\n",
    "    V = ForwardDiff.hessian(f, [θ_2])\n",
    "    V = V[1]\n",
    "    V = V^(-1)\n",
    "\n",
    "  \n",
    "    return (θ_2 = θ_2, V = V)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = 10^4\n",
    "cover = zeros(3)\n",
    "for i in 1:R\n",
    "    (Y, X, Z1, Z2) = data(200)\n",
    "    (θ, V)  = TwoStepGMM(Y, X, Z1, Z2)\n",
    "    cover[1] +=   (abs(θ - θ_0) < quantile(Normal(0,1), 1 - 0.1/2) * sqrt(V/200)) /R\n",
    "    cover[2] +=   (abs(θ - θ_0) < quantile(Normal(0,1), 1 - 0.05/2) * sqrt(V/200)) /R\n",
    "    cover[3] +=   (abs(θ - θ_0) < quantile(Normal(0,1), 1 - 0.01/2) * sqrt(V/200)) /R\n",
    "end\n",
    "\n",
    "header = [\"α = 0.1\", \"α = 0.05\", \"α = 0.01\"]\n",
    "cover = cover'\n",
    "pretty_table(cover; header = header)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the simulated coverage probability is pretty close to their nominal coverage level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
