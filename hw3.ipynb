{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "Pkg.activate(joinpath(pwd(),\"..\"))\n",
    "using Random, Distributions, Plots, LaTeXStrings, PrettyTables\n",
    "Random.seed!(123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Π(λ,k; R = 10^5 )\n",
    "    n_1 = length(λ)\n",
    "    n_2 = length(k)\n",
    "    Π = zeros(n_1, n_2)\n",
    "\n",
    "    for i in 1:n_2\n",
    "        ki = k[i]\n",
    "        z = randn(ki,R)\n",
    "        cv_vec = quantile.(Chisq.(ki),0.95) .* ones(R)\n",
    "        nc = zeros(ki)\n",
    "        for j in 1:n_1\n",
    "            λj = λ[j]\n",
    "            nc[1] = λj\n",
    "            x_raw = (z .+ nc).^2\n",
    "            x = sum(x_raw; dims = 1)\n",
    "            t = x .> cv_vec'\n",
    "            Π[j,i] = R^(-1) * sum(t)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    return Π\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1,5,10]\n",
    "λ = [0]\n",
    "Π0 = Π(λ, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we set $\\lambda = 0 $, we are actually making all the $X$'s to follow a central $\\chi^2_k$ distribution. Therefore, given such a large repetition times, we expect the result to be close to $\\alpha$, the type I error we set. As we can see, the results are pretty close to 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = [1,5,10]\n",
    "λ = 0:0.1:6\n",
    "errors = Π(λ, k)\n",
    "\n",
    "plot(λ,errors[:,1],label = L\"k=1\")\n",
    "plot!(λ,errors[:,2],label=L\"k=5\")\n",
    "plot!(λ,errors[:,3],label=L\"k=10\",legend=:topleft)\n",
    "plot!(xlabel=L\"\\lambda\",ylabel=L\"\\pi(\\lambda,k)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the figure that when $k = 1 $, the power increases and converges to 1 the fastest, as $\\lambda$ increases. As $k$ increases, the increase of power becomes slower at a decreasing rate. We can imagine that the line of $k = 100$ and $k = 200$ won't differ so much."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting hyper-parameters\n",
    "const δ = 0.5\n",
    "const β1 = 1 \n",
    "const π1 = 1\n",
    "const k2 = 2\n",
    "const β2 = ones(k2)\n",
    "const π2 = ones(k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function data_generating(n)\n",
    "\n",
    "    #Generate exogeneous variables\n",
    "    mvnormal = MvNormal([0;0], [1 0 ; 0 1])\n",
    "    V = randn(n,1)\n",
    "    ϵ = randn(n,1)\n",
    "    X2 = rand(mvnormal,n )'\n",
    "    Z = randn(n,1)\n",
    "\n",
    "    #Generate endogenous variables\n",
    "    U = δ * V + ϵ\n",
    "    X1 = π1 .* Z .+ X2 * π2 + V\n",
    "    Y = β1 .* X1 + X2 * β2 + U\n",
    "\n",
    "    return (Y = Y, X1 = X1, X2 = X2, Z = Z)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30\n",
    "(Y, X1, X2, Z) = data_generating(n)\n",
    "X1,X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function SimulationBias1( n ; R = 10^5)\n",
    "    errors = zeros(R)\n",
    "    for i in 1:R\n",
    "        (Y, X1, X2, Z) = data_generating(n)\n",
    "        x = [X1 X2]\n",
    "        z = [Z X2]\n",
    "\n",
    "        n_1 = size(Y,1)\n",
    "        Q = (z'* x)/n_1\n",
    "        W = inv(z' * z/n_1)\n",
    "\n",
    "        beta2SLS = (Q' * W * Q)^(-1) * Q' * W * (z' * Y)/n_1\n",
    "        errors[i] = beta2SLS[1] - β1\n",
    "    end\n",
    "\n",
    "    bias = R^(-1) * sum(errors)\n",
    "    return (bias = bias)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function SimulationBias2(n; R = 10^5)\n",
    "    errors = zeros(R)\n",
    "    for i in 1:R\n",
    "        (Y, X1, X2, Z) = data_generating(n)\n",
    "        x = [X1 X2]\n",
    "        Z2 = Z.^2\n",
    "        X22 = X2.^2\n",
    "        Z3 = Z.^3\n",
    "        X23 = X2.^3\n",
    "        ZX = Z .* X2\n",
    "        ZX2 = Z2 .* X22\n",
    "        ZX3 = Z3 .* X23\n",
    "        ZXX = Z .* X2[:,1] .* X2[:,2]\n",
    "\n",
    "        z = [Z X2 Z2 X22 Z3 X23 ZX ZX2 ZX3 ZXX]\n",
    "    \n",
    "\n",
    "        n_1 = size(Y,1)\n",
    "        Q = (z'* x)/n_1\n",
    "        W = inv(z' * z/n_1)\n",
    "\n",
    "        beta2SLS = (Q' * W * Q)^(-1) * Q' * W * (z' * Y)/n_1\n",
    "        errors[i] = beta2SLS[1] - β1\n",
    "    end\n",
    "\n",
    "    bias = R^(-1) * sum(errors)\n",
    "    return (bias = bias)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function Bias(ns::Array)\n",
    "    n_length = size(ns,1)\n",
    "    Bias = zeros(n_length,3)\n",
    "    for i in 1:n_length\n",
    "        ni = ns[i]\n",
    "        Bias[i,1] = ni\n",
    "        Bias[i,2] = SimulationBias1(ni)\n",
    "        Bias[i,3] = SimulationBias2(ni)\n",
    "    end\n",
    "    return Bias\n",
    "end       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [30, 100, 1000]\n",
    "result = Bias(ns)\n",
    "header = [\"Sample Size(n)\", \"Bias\", \"Bias with Many IVs\"]\n",
    "pretty_table(result; header = header, alignment=:L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table we can see that, with many IVs, the bias tends to be larger than that with 2 IVs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that as n grows larger, both bias are smaller, but the relative relationships are not changed. Bias with many IVs would be approximately 10 times larger."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
