{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Desktop/MachineLearning`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TaskLocalRNG()"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Pkg\n",
    "Pkg.activate(joinpath(pwd(),\"..\"))\n",
    "using Random, Distributions, PrettyTables, SCS, Plots, LinearAlgebra, Convex\n",
    "using Base.Threads: @threads, @spawn\n",
    "Random.seed!(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function data(n, k, ρ, σ, β₁, β₂)\n",
    "    #Set covariance matrix\n",
    "    Σ = ρ .* ones(k,k)\n",
    "    Σ[diagind(Σ)] .= 1\n",
    "    μ = zeros(k)\n",
    "    mvnormal = MvNormal(μ,Σ)\n",
    "    X = rand(mvnormal, n)'\n",
    "\n",
    "    normal = Normal(0, σ^2)\n",
    "    U = rand(normal, n)\n",
    "    x1 = X[:,1]\n",
    "    x2 = X[:,2]\n",
    "    Y = 1 .+ β₁ .* x1 + β₂ .* x2 .+ U\n",
    "\n",
    "    return( Y = Y, X = X)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MathOptInterface.OptimizerWithAttributes(SCS.Optimizer, Pair{MathOptInterface.AbstractOptimizerAttribute, Any}[MathOptInterface.RawOptimizerAttribute(\"eps_abs\") => 1.0e-8, MathOptInterface.RawOptimizerAttribute(\"eps_rel\") => 1.0e-8, MathOptInterface.Silent() => true])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MOI = Convex.MOI\n",
    "opt = MOI.OptimizerWithAttributes(SCS.Optimizer, \"eps_abs\"=>1.0e-08, \"eps_rel\"=>1.0e-08, MOI.Silent() => true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lasso (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function lasso(Y, X, λ)\n",
    "    n = length(Y)\n",
    "    X = [X ones(n,1)]\n",
    "    k = size(X, 2)\n",
    "\n",
    "    b = Variable(k)\n",
    "    Q = X'X / 2n\n",
    "    c = X'Y / 2n                    #c'b = Y'X*b\n",
    "\n",
    "    L1 = quadform(b, Q)            #b'Q*b\n",
    "    L2 = dot(c, b)                 #c'b\n",
    "    L3 = norm(b[1:k-1], 1)                #sum(|b|)\n",
    "    \n",
    "\n",
    "    Q = minimize(L1 - 2 * L2 + λ * L3) \n",
    "    solve!(Q, opt,verbose=false)\n",
    "\n",
    "    return b = round.(vec(evaluate(b)),digits=5)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MC (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function MC(ρ, σ, β₁, β₂, R, n, k)\n",
    "    λ = 1.1 * σ * sqrt(2 * log(n*k)/n)\n",
    "    p1 = 0\n",
    "    p2 = 0\n",
    "    p3 = 0\n",
    "    @threads for i in 1:R\n",
    "        (Y, X) = data(n, k, ρ, σ, β₁, β₂)\n",
    "        b = lasso(Y, X, λ)\n",
    "        p1 += (b[1] != 0)/R\n",
    "        p2 += (b[2] != 0)/R\n",
    "        p3 += (norm(b[3:k]) != 0)/R\n",
    "    end\n",
    "    return (p1 = round(p1, digits = 5), p2 = round(p2, digits = 5), p3 = round(p3, digits = 5))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (e) - (g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "┌─────────┬─────────────┬─────────────┬──────────────────────────────┐\n",
      "│\u001b[1m         \u001b[0m│\u001b[1m Select Xi,1 \u001b[0m│\u001b[1m Select Xi,2 \u001b[0m│\u001b[1m Select Irrelevant Regressors \u001b[0m│\n",
      "├─────────┼─────────────┼─────────────┼──────────────────────────────┤\n",
      "│ Group 1 │         1.0 │         1.0 │                        0.797 │\n",
      "│ Group 2 │         1.0 │         1.0 │                          0.0 │\n",
      "│ Group 3 │         1.0 │       0.117 │                        0.672 │\n",
      "│ Group 4 │       0.927 │       0.933 │                        0.991 │\n",
      "└─────────┴─────────────┴─────────────┴──────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "(p11, p12, p13) = MC(0.2, 2, 2, 2, 1000, 300, 50)\n",
    "(p21, p22, p23) = MC(0.2, 0.1, 0.1, 0.1, 1000, 300, 50)\n",
    "(p31, p32, p33) = MC(0.2, 2, 2, 0.2, 1000, 300, 50)\n",
    "(p41, p42, p43) = MC(0.9, 2, 2, 2, 1000, 300, 50)\n",
    "\n",
    "\n",
    "result = [\"Group 1\" p11 p12 p13; \"Group 2\" p21 p22 p23; \"Group 3\" p31 p32 p33; \"Group 4\" p41 p42 p43]\n",
    "header = [\" \", \"Select Xi,1\", \"Select Xi,2\", \"Select Irrelevant Regressors\"]\n",
    "pretty_table(result; header = header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In part (c), Lasso doesn't correctly select true model. It frequently include irrelevant regressors.\n",
    "\n",
    "Compare with result from part (d), both procedure selected $X_{i,1}$ and $X_{i,2}$ correctly, but in part (d), no irrelevant regressors were selected. I guess it's because $\\sigma^2 = EU_i^2$ is large in part (c), so the model overfitted to reduce the creterion function, since a part of it can be interpreted as $\\frac{1}{2n} \\sum \\hat{U}_i^2$\n",
    "\n",
    "From part (c) to part (e), we make the effect of $X_{i,2}$ very small, therefore, it can be expected that the probability of selecting $X_{i,2}$ will be significantly lowered since its effect can be too small to be identified. Moreover, the fact that the probability of selecting $X_{i,2}$ or irrelevant regressors in part (e) is roughly the same as probability of selecting irrelevant regressors in part (c) is also an evidence that the effect of $X_{i,2}$ is not identified.\n",
    "\n",
    "From part (c) to part (f), we increased the covariance between X's. As the X's are more correlated, part of $X_{i,1}$ and $X_{i,2}$'s effects can be misallocated to other X's. We expect the probability of including irrelevant regressors will be higher, and it of selecting $X_{i,1}$ and $X_{i,2}$ correctly will be lower. The result is the same as our expection."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia(10 threads) 1.7.2",
   "language": "julia",
   "name": "julia(10-threads)-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
